{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categorie1</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFORMATIQUE</td>\n",
       "      <td>batter acer aspir one yr li ion mah wh noir co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TELEPHONIE - GPS</td>\n",
       "      <td>coqu rigid bleu lagon pour alcatel ot motif dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TELEPHONIE - GPS</td>\n",
       "      <td>facad et coqu cellular lin shckgal minip marqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TELEPHONIE - GPS</td>\n",
       "      <td>coqu meteor tpu lg nexus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TELEPHONIE - GPS</td>\n",
       "      <td>coqu soupl transparent pour lg flex motif keep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>BRICOLAGE - OUTILLAGE - QUINCAILLERIE</td>\n",
       "      <td>vis tet cylindr toolcraft din aci mm pc conten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>INSTRUMENTS DE MUSIQUE</td>\n",
       "      <td>cord thomastik violon domin noyau plein nylon ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>ELECTROMENAGER</td>\n",
       "      <td>puissanc pression maximal bar reservoir amovib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>VETEMENTS - LINGERIE</td>\n",
       "      <td>gilet hop lif yedo noir nouvel collect de la l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>TELEPHONIE - GPS</td>\n",
       "      <td>casqu stereo coloud color avec micro integr co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Categorie1  \\\n",
       "0                                INFORMATIQUE   \n",
       "1                            TELEPHONIE - GPS   \n",
       "2                            TELEPHONIE - GPS   \n",
       "3                            TELEPHONIE - GPS   \n",
       "4                            TELEPHONIE - GPS   \n",
       "...                                       ...   \n",
       "999995  BRICOLAGE - OUTILLAGE - QUINCAILLERIE   \n",
       "999996                 INSTRUMENTS DE MUSIQUE   \n",
       "999997                         ELECTROMENAGER   \n",
       "999998                  VETEMENTS - LINGERIE    \n",
       "999999                       TELEPHONIE - GPS   \n",
       "\n",
       "                                              Description  \n",
       "0       batter acer aspir one yr li ion mah wh noir co...  \n",
       "1       coqu rigid bleu lagon pour alcatel ot motif dr...  \n",
       "2       facad et coqu cellular lin shckgal minip marqu...  \n",
       "3                               coqu meteor tpu lg nexus   \n",
       "4       coqu soupl transparent pour lg flex motif keep...  \n",
       "...                                                   ...  \n",
       "999995  vis tet cylindr toolcraft din aci mm pc conten...  \n",
       "999996  cord thomastik violon domin noyau plein nylon ...  \n",
       "999997  puissanc pression maximal bar reservoir amovib...  \n",
       "999998  gilet hop lif yedo noir nouvel collect de la l...  \n",
       "999999  casqu stereo coloud color avec micro integr co...  \n",
       "\n",
       "[1000000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#le data frame est saved à partir de Help_rapport \n",
    "data_cleaned = pd.read_csv(\"data/data_cleaned_1M.csv\").fillna(\"\")\n",
    "data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['batter', 'acer', 'aspir', 'one', 'yr', 'li', 'ion', 'mah', 'wh', 'noir', 'compatibl', 'batter', 'la'], ['coqu', 'rigid', 'bleu', 'lagon', 'pour', 'alcatel', 'ot', 'motif', 'drapeau', 'liberi', 'film', 'coqu', 'rigid', 'ultra', 'fin', 'bleu', 'lagon', 'original', 'de', 'muzzano', 'au', 'motif', 'drapeau', 'liberi', 'pour', 'alcatel', 'la'], ['facad', 'et', 'coqu', 'cellular', 'lin', 'shckgal', 'minip', 'marqu', 'agree', 'samsungmobil', 'compatibl', 'galaxy', 'minimatier', 'caoutchouc', 'soupl', 'la'], ['coqu', 'meteor', 'tpu', 'lg', 'nexus'], ['coqu', 'soupl', 'transparent', 'pour', 'lg', 'flex', 'motif', 'keep', 'calm', 'and', 'play', 'football', 'coqu', 'soupl', 'ultra', 'fin', 'transparent', 'original', 'de', 'muzzano', 'au', 'motif', 'keep', 'calm', 'and', 'play', 'footbal', 'la']]\n"
     ]
    }
   ],
   "source": [
    "## On s'est rendu compte que le dernier token était \"\" pour chaque produit\n",
    "train_array_token = [line.split(' ') for line in data_cleaned.Description.values]\n",
    "print(train_array_token[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_dimension = 500\n",
    "hs = 0\n",
    "negative = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start learning skip-gram Word2Vec\n",
      "Learning time : 699.03 seconds Word2Vec\n"
     ]
    }
   ],
   "source": [
    "sg = 1\n",
    "print(\"Start learning skip-gram Word2Vec\")\n",
    "ts = time.time()\n",
    "model_sg = gensim.models.Word2Vec(train_array_token, sg=sg, hs=hs, negative=negative, min_count=1, size=Features_dimension)\n",
    "te = time.time()\n",
    "t_learning = te-ts\n",
    "print(\"Learning time : %.2f seconds Word2Vec\" %t_learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction qui crée la list de features\n",
    "\n",
    "def set_features(array_token_prod,dim_feature,model):\n",
    "    features= []\n",
    "    #on prend les tokens de chaque produit\n",
    "    for token_prod in array_token_prod:\n",
    "        #on crée le np final du produit\n",
    "        feat_prod= np.zeros(dim_feature)\n",
    "        # on prend chaque token dans la desc prod\n",
    "        for token in token_prod:\n",
    "            #on somme les vecteurs et on divise direct par le nombre de token\n",
    "            feat_prod +=model[token]/len(token_prod)\n",
    "            \n",
    "        #on rajoute le vectuer moyenné produit dans la list features\n",
    "        features += [feat_prod]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulbrunet/anaconda3/envs/Projet4A/lib/python3.7/site-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "#init notre list de features\n",
    "features=set_features(train_array_token,Features_dimension,model_sg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a bien 100 000 vecteurs colonne de dim 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on va split comme précédemment avec ces nvx features et label\n",
    "label = data_cleaned[\"Categorie1\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(features,label, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procédure habituelle ensuite.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulbrunet/anaconda3/envs/Projet4A/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "789.879961013794 sec\n"
     ]
    }
   ],
   "source": [
    "ts = time.time()\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "te = time.time()\n",
    "print(te-ts, \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score apprentissage  0.9030055555555555\n",
      "Score test  0.90134\n"
     ]
    }
   ],
   "source": [
    "print(\"Score apprentissage \",lr.score(X_train,y_train))\n",
    "print(\"Score test \",lr.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autre modèle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg = 0\n",
    "print(\"Start learning CBOW Word2Vec\")\n",
    "ts = time.time()\n",
    "model_cbow = gensim.models.Word2Vec(train_array_token, sg=sg, hs=hs, negative=negative, min_count=1, size=Features_dimension)\n",
    "te = time.time()\n",
    "t_learning = te-ts\n",
    "print(\"Learning time : %.2f seconds Word2Vec\" %t_learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features2=set_features(train_array_token,Features_dimension,model_cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(features2,label, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "lr2 = LogisticRegression()\n",
    "lr2.fit(X_train2, y_train2)\n",
    "te = time.time()\n",
    "print(te-ts, \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Score apprentissage \",lr2.score(X_train2,y_train2))\n",
    "print(\"Score test \",lr2.score(X_test2,y_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration utilisation modèle/token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sg.most_similar([\"montr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cbow.most_similar([\"montr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sg[\"montr\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#faire tourner sg sur le max de données avec données nettoyées\n",
    "#puis prediction avec la regression à comparer le mm modele avec les features de count vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pre-trained network\n",
    "\n",
    "\n",
    "Github du projet[https://github.com/Kyubyong/wordvectors](https://github.com/Kyubyong/wordvectors) appris sur 1Giga d'articles de wikipedia en mode **Skip-Gram*\n",
    "\n",
    "Vous pouvez télécharger ce modèle en suivant ce [lien](https://drive.google.com/file/d/0B0ZXk88koS2KM0pVTktxdG15TkE/view). Dezipez-le puis téléchargez le modèle en indiquant la direction du fichier \"fr/bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_online_dir = \"data/fr/fr.bin\"\n",
    "#model_online_dir = \"ACOMPLETER/fr.bin\"\n",
    "model_online = gensim.models.Word2Vec.load(model_online_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
